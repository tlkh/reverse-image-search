{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this code does\n",
    "In short, it is a reverse meme search, that identifies the source of the meme. It takes an image copypasta, extracts the individual *subimages* and compares it with a database of pictures (the database should be made up of copypastas, which is in TODO)\n",
    "\n",
    "### TODO\n",
    "\n",
    "### Clean up the code\n",
    "There are many repetitive import statements. <br\\>\n",
    "The code is saving the picture as file so that you can load it into model. <br\\>\n",
    "Anything that you cannot explain in this code <br\\>\n",
    "Change VGG16 to Xception (because I can't upgrade both TF and keras for reasons)\n",
    "\n",
    "#### Feature vector robustness check\n",
    "To what extent the following transformations affects the feature vector?\n",
    "- crop (a little, add bounding boxes)\n",
    "- photoshop - e.g. cropping a face onto a body\n",
    "- rotate the image (a little, a lot)\n",
    "- add text (different sizes)\n",
    "- vandalised - scribbling markers over \n",
    "- add noise (Gaussian etc)\n",
    "- compression changes\n",
    "- recoloring - grey-scale\n",
    "- picture effects - e.g. twisted picture meme\n",
    "- special effects - e.g. shining eyes meme\n",
    "\n",
    "#### Image separation testing\n",
    "We need to ensure the individual pictures are separated correctly.\n",
    "- pictures now don't have borders\n",
    "- pictures are no longer rectangular\n",
    "- whether does it identify the source of the cropped face\n",
    "\n",
    "#### Database management\n",
    "We need to do preprocessing of the database. Currently the feature vector is only calculated when you start this notebook. \n",
    "\n",
    "Moreover, since the database of copypasta will not be single images, we need to process that aspect as well. From the copypastas we need to identify its subimages and then calculate their feature vector. There also needs to be some way to associate the feature vector and the location of the subimages to the image copypasta, together with its metadata - in a manner that is scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import imagenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run image_database_helper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making a list of all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: imgs/.DS_Store: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm 'imgs/.DS_Store'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "images = findfiles(\"new/\")\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fieldnames = ['img_file_name',\n",
    "              'number_of_subimages',\n",
    "              'subimage_number',\n",
    "              'x',\n",
    "              'y',\n",
    "              'w',\n",
    "              'h',\n",
    "              'feature_vector']\n",
    "\n",
    "import os\n",
    "if not os.path.exists('index_subimage.csv'):\n",
    "    with open('index_subimage.csv', 'w') as csvfile:\n",
    "        db = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        db.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our-singapore-malaysian-durian-fake-768x791.jpg\n",
      "dog-meat-satay-post.jpg\n",
      "Screen Shot 2018-04-02 at 05.19.52 AM.png\n",
      "Screen-Shot-2017-10-12-at-5.33.37-PM.png\n",
      "ge14fakenews.png\n",
      "pm-lee-gst-meme.jpg\n",
      "casket-1-768x1366.jpg\n",
      "17626490_10155249769684175_8841223787064818741_n.jpg\n",
      "city-harvest-church-headline-changed.jpg\n",
      "17951666_1758817064340674_3343590308811084675_n-768x1365.jpg\n",
      "sexdoll-768x603.jpg\n",
      "pmo-lky-hoax.jpg\n",
      "Bear-hoax-singapore-768x432.jpg\n",
      "notice-sammyboy-e1520150158500-768x620.jpg\n",
      "ntucfairpricewarning.jpg\n",
      "IMG_7EF6C6D23BCD-1-768x1366.jpg\n",
      "ntuc27e_2x.jpg\n",
      "flyer-breast-cancer-yishun-fake.jpg\n",
      "Punggo_Waterway_Terraces_roof_top_floors_collapse_1-768x801.jpg\n",
      "cross-with-phone-fine-fake-768x930.jpg\n",
      "fake copy.jpg\n",
      "Screen-Shot-2018-02-09-at-10.26.30.png\n",
      "ASS-Prakash-2-768x787.jpg\n",
      "nude-2.jpg\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import csv\n",
    "\n",
    "\n",
    "for img_name in images:\n",
    "    path_image_to_analyse = \"./new/\"+img_name\n",
    "    print(img_name)\n",
    "    \n",
    "    img = cv2.imread(path_image_to_analyse)\n",
    "    output_boxes = get_bounding_boxes(img)\n",
    "\n",
    "    for i, box in enumerate(output_boxes):\n",
    "        [x,y,w,h] = box\n",
    "        output_img = np.array(img[y:y+h, x:x+w])\n",
    "        cv2.imwrite(\"temp.jpg\",output_img)\n",
    "        feature_vector = calc_feature_vector(model, \"temp.jpg\")\n",
    "\n",
    "        dict_to_write = {'img_file_name':img_name,\n",
    "                      'number_of_subimages':len(output_boxes),\n",
    "                      'subimage_number':i,\n",
    "                      'x':x,\n",
    "                      'y':y,\n",
    "                      'w':w,\n",
    "                      'h':h,\n",
    "                      'feature_vector':feature_vector}\n",
    "\n",
    "        with open('index_subimage.csv', 'a') as csvfile:\n",
    "            db = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            db.writerow(dict_to_write)\n",
    "    \n",
    "    subprocess.run(\"mv ./new/{} ./database/{}\".format(img_name,img_name),shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cp ./database/* ./new/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
